{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892d52bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation \n",
    "from pyts.image import MarkovTransitionField\n",
    "import dask.dataframe as dd  \n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from scipy import signal as sign\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165f63d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = dd.read_parquet(\"dataset/train.parquet\", engine=\"pyarrow\")\n",
    "df_metadata = pd.read_csv('dataset/metadata_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba64c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = ddf[\"706\"].compute()\n",
    "\n",
    "fs = 8e5/20e-3\n",
    "\n",
    "f, t, Sxx = sign.spectrogram(signal, fs)\n",
    "\n",
    "print(f.shape, t.shape, Sxx.shape)\n",
    "\n",
    "plt.pcolormesh(t, f, Sxx, shading='gouraud')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad116ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,255))\n",
    "Sxx = scaler.fit_transform(Sxx)\n",
    "\n",
    "img = Image.fromarray(Sxx).resize((1024, 768))\n",
    "\n",
    "\n",
    "plt.imshow(img)\n",
    "img = np.array(img)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40ac3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ddf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516ff857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "images = []\n",
    "fs = 8e5/20e-3 # Sampling frequency\n",
    "img_size = 256, 256 # Size for all images \n",
    "\n",
    "\n",
    "for col in tqdm(ddf.columns):\n",
    "    # Get signal\n",
    "    signal = ddf[str(col)].compute()\n",
    "\n",
    "    # Get spectrogram from signal\n",
    "    f, t, Sxx = sign.spectrogram(signal, fs)\n",
    "    # Transform spectrogram to image range (0, 255)\n",
    "    scaler = MinMaxScaler(feature_range=(0,255))\n",
    "    Sxx = scaler.fit_transform(Sxx)\n",
    "    # Resize image\n",
    "    img = np.array(Image.fromarray(Sxx).resize(img_size))\n",
    "    images.append(img)\n",
    "    \n",
    "images = np.array(images).reshape((len(ddf.columns), 256, 256, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f0234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"dataset/images.npy\", images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8f5669",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_metadata[[\"target\"]]\n",
    "np.save(\"dataset/labels.npy\", labels)\n",
    "print(labels)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c4e373",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "n_signal = 0\n",
    "fig = plt.figure() # make figure\n",
    "im = plt.imshow(images[0], cmap='gray')\n",
    "\n",
    "# function to update figure\n",
    "def updatefig(j):\n",
    "    # set the data in the axesimage object\n",
    "    im.set_array(images[j])\n",
    "    fig.suptitle(str(j))\n",
    "    # return the artists set\n",
    "    return [im]\n",
    "# kick off the animation\n",
    "ani = animation.FuncAnimation(fig, updatefig, \n",
    "                              interval=10, blit=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d23780",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_data, X_test, y_data, y_test = train_test_split(images, labels, test_size=0.3, random_state=42, stratify=labels)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=0.2, random_state=42, stratify=y_data)\n",
    "\n",
    "np.save(\"dataset/train/images_train.npy\", X_train)\n",
    "np.save(\"dataset/train/labels_train.npy\", y_train)\n",
    "np.save(\"dataset/test/images_test.npy\", X_test)\n",
    "np.save(\"dataset/test/labels_test.npy\", y_test)\n",
    "np.save(\"dataset/val/images_val.npy\", X_val)\n",
    "np.save(\"dataset/val/labels_val.npy\", y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad422e22",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ac5bc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation \n",
    "from pyts.image import MarkovTransitionField\n",
    "import dask.dataframe as dd  \n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from scipy import signal as sign\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b91604a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 14:12:50.202411: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-28 14:12:50.388602: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-09-28 14:12:50.462871: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-09-28 14:12:51.148368: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:\n",
      "2022-09-28 14:12:51.148434: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:\n",
      "2022-09-28 14:12:51.148438: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "X_train = np.load(\"dataset_spectrogram/train/images_train.npy\")\n",
    "y_train = np.load(\"dataset_spectrogram/train/labels_train.npy\")\n",
    "X_test = np.load(\"dataset_spectrogram/test/images_test.npy\")\n",
    "y_test = np.load(\"dataset_spectrogram/test/labels_test.npy\")\n",
    "X_val = np.load(\"dataset_spectrogram/val/images_val.npy\")\n",
    "y_val = np.load(\"dataset_spectrogram/val/labels_val.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53819223",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "009bedd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 256)     2560      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 127, 127, 256)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 128)     295040    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 62, 62, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 64)        73792     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 230400)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                14745664  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,117,121\n",
      "Trainable params: 15,117,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 13:09:49.051784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-28 13:09:49.135548: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-28 13:09:49.135711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-28 13:09:49.136618: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-28 13:09:49.137787: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-28 13:09:49.137912: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-28 13:09:49.137988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-28 13:09:49.623528: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-28 13:09:49.623928: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-28 13:09:49.624016: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-28 13:09:49.624095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4117 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Creaci贸n de modelo\n",
    "model = models.Sequential()\n",
    "# Capas encargadas de obtener informaci贸n de la imagen\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu', input_shape=(256,256,1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# Capas para la clasificaci贸n en base a la informaci贸n obtenida en \n",
    "# capas anteriores\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation = 'sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f39438d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 13:09:58.151126: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8300\n",
      "2022-09-28 13:09:59.521649: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-09-28 13:09:59.521693: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-09-28 13:09:59.559658: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-09-28 13:09:59.559686: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-09-28 13:09:59.625973: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.36GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-09-28 13:09:59.626025: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.36GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-09-28 13:09:59.681234: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 884.50MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-09-28 13:09:59.681283: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 884.50MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-09-28 13:09:59.722962: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/488 [============================>.] - ETA: 0s - loss: 3.8341 - accuracy: 0.9300 - recall: 0.1088"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 13:11:05.509378: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.02GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-09-28 13:11:05.509407: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.02GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488/488 [==============================] - ETA: 0s - loss: 3.8279 - accuracy: 0.9301 - recall: 0.1088\n",
      "Epoch 1: saving model to CNN-model.ckpt\n",
      "488/488 [==============================] - 74s 140ms/step - loss: 3.8279 - accuracy: 0.9301 - recall: 0.1088 - val_loss: 0.1402 - val_accuracy: 0.9459 - val_recall: 0.1781\n",
      "Epoch 2/100\n",
      "488/488 [==============================] - ETA: 0s - loss: 0.1588 - accuracy: 0.9451 - recall: 0.1803\n",
      "Epoch 2: saving model to CNN-model.ckpt\n",
      "488/488 [==============================] - 66s 136ms/step - loss: 0.1588 - accuracy: 0.9451 - recall: 0.1803 - val_loss: 0.1769 - val_accuracy: 0.9443 - val_recall: 0.0822\n",
      "Epoch 3/100\n",
      "488/488 [==============================] - ETA: 0s - loss: 0.1195 - accuracy: 0.9584 - recall: 0.4320\n",
      "Epoch 3: saving model to CNN-model.ckpt\n",
      "488/488 [==============================] - 66s 135ms/step - loss: 0.1195 - accuracy: 0.9584 - recall: 0.4320 - val_loss: 0.1370 - val_accuracy: 0.9492 - val_recall: 0.1918\n",
      "Epoch 4/100\n",
      "488/488 [==============================] - ETA: 0s - loss: 0.0837 - accuracy: 0.9699 - recall: 0.6020\n",
      "Epoch 4: saving model to CNN-model.ckpt\n",
      "488/488 [==============================] - 66s 135ms/step - loss: 0.0837 - accuracy: 0.9699 - recall: 0.6020 - val_loss: 0.1548 - val_accuracy: 0.9434 - val_recall: 0.4521\n",
      "Epoch 5/100\n",
      "488/488 [==============================] - ETA: 0s - loss: 0.0475 - accuracy: 0.9846 - recall: 0.8061\n",
      "Epoch 5: saving model to CNN-model.ckpt\n",
      "488/488 [==============================] - 66s 136ms/step - loss: 0.0475 - accuracy: 0.9846 - recall: 0.8061 - val_loss: 0.1628 - val_accuracy: 0.9533 - val_recall: 0.5890\n",
      "Epoch 6/100\n",
      "488/488 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9893 - recall: 0.8844\n",
      "Epoch 6: saving model to CNN-model.ckpt\n",
      "488/488 [==============================] - 66s 136ms/step - loss: 0.0318 - accuracy: 0.9893 - recall: 0.8844 - val_loss: 0.1758 - val_accuracy: 0.9566 - val_recall: 0.4521\n",
      "Epoch 7/100\n",
      "488/488 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.9883 - recall: 0.8605\n",
      "Epoch 7: saving model to CNN-model.ckpt\n",
      "488/488 [==============================] - 66s 135ms/step - loss: 0.0326 - accuracy: 0.9883 - recall: 0.8605 - val_loss: 0.6429 - val_accuracy: 0.9410 - val_recall: 0.0548\n",
      "Epoch 8/100\n",
      "488/488 [==============================] - ETA: 0s - loss: 0.0308 - accuracy: 0.9930 - recall: 0.9252\n",
      "Epoch 8: saving model to CNN-model.ckpt\n",
      "488/488 [==============================] - 66s 136ms/step - loss: 0.0308 - accuracy: 0.9930 - recall: 0.9252 - val_loss: 0.3873 - val_accuracy: 0.9590 - val_recall: 0.3562\n",
      "Epoch 9/100\n",
      "488/488 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 0.9938 - recall: 0.9286\n",
      "Epoch 9: saving model to CNN-model.ckpt\n",
      "488/488 [==============================] - 66s 135ms/step - loss: 0.0275 - accuracy: 0.9938 - recall: 0.9286 - val_loss: 0.1916 - val_accuracy: 0.9590 - val_recall: 0.6575\n",
      "Epoch 10/100\n",
      "488/488 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9957 - recall: 0.9558\n",
      "Epoch 10: saving model to CNN-model.ckpt\n",
      "488/488 [==============================] - 66s 135ms/step - loss: 0.0107 - accuracy: 0.9957 - recall: 0.9558 - val_loss: 0.4043 - val_accuracy: 0.9475 - val_recall: 0.6301\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(patience = 7)\n",
    "\n",
    "checkpoint_path='CNN-model.ckpt'\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "model.compile(loss = 'bce', optimizer = 'adam', metrics=['accuracy', tf.keras.metrics.Recall()])\n",
    "history_cnn = model.fit(X_train, y_train, epochs=100, \n",
    "                        validation_data=(X_val, y_val),\n",
    "                        batch_size=10,\n",
    "                        callbacks=[early_stopping, cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0be36fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_cnn.history['accuracy'], label='accuracy')\n",
    "plt.plot(history_cnn.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d55fde08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_cnn.history['loss'], label='loss')\n",
    "plt.plot(history_cnn.history['val_loss'], label = 'val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "# plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a524946d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305/305 - 3s - loss: 0.4043 - accuracy: 0.9475 - recall: 0.6301 - 3s/epoch - 10ms/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_recall = model.evaluate(X_val,  y_val, verbose=2, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "994f37cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305/305 [==============================] - 3s 9ms/step\n",
      "[0 0 0 ... 0 0 1]\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "predictions = (model.predict(X_val, batch_size=4)>0.5).reshape(1,-1)[0].astype(int)\n",
    "# predictions = model.predict(X_val, batch_size=10)\n",
    "# class_predictions = np.argmax(predictions,axis=1)\n",
    "real_values = y_val.T[0]\n",
    "\n",
    "print(predictions)\n",
    "print(real_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b4394cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "654/654 - 6s - loss: 0.3977 - accuracy: 0.9350 - recall: 0.4430 - 6s/epoch - 10ms/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_recall = model.evaluate(X_test,  y_test, verbose=2, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f74c537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "654/654 [==============================] - 6s 9ms/step\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "predictions = (model.predict(X_test, batch_size=4)>0.5).reshape(1,-1)[0].astype(int)\n",
    "# predictions = model.predict(X_val, batch_size=10)\n",
    "real_values = y_test.T[0]\n",
    "\n",
    "print(predictions)\n",
    "print(real_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fd4dc5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4171480707541146"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "matthews_corrcoef(real_values, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed115317",
   "metadata": {},
   "source": [
    "# Resnet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eedd409f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 14:13:04.836284: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-28 14:13:04.919881: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-28 14:13:04.920007: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-28 14:13:04.920457: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-28 14:13:04.921690: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-28 14:13:04.921829: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-28 14:13:04.921904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-28 14:13:05.397031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-28 14:13:05.397461: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-28 14:13:05.397551: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-28 14:13:05.397633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4117 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Transfer Learning\n",
    "base_model = tf.keras.applications.ResNet50(include_top=False, weights='imagenet', input_shape=(256, 256, 3))\n",
    "avg = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(avg)\n",
    "\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False # Esto impide que las capas se re entrenen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e224b796",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rgb = np.repeat(X_train, 3, -1)\n",
    "X_val_rgb = np.repeat(X_val, 3, -1)\n",
    "\n",
    "del X_train\n",
    "del X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740730a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 14:13:27.728563: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "   1/4878 [..............................] - ETA: 5:24:36 - loss: 1.1050 - accuracy: 0.0000e+00 - recall: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 14:13:29.022958: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4877/4878 [============================>.] - ETA: 0s - loss: 0.1760 - accuracy: 0.9420 - recall: 0.3163"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(patience = 7)\n",
    "\n",
    "checkpoint_path='Resnet50-model.ckpt'\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "model.compile(loss = 'bce', optimizer = 'adam', metrics=['accuracy', tf.keras.metrics.Recall()])\n",
    "history_cnn = model.fit(X_train_rgb, y_train, epochs=100, \n",
    "                        validation_data=(X_val_rgb, y_val),\n",
    "                        batch_size=1,\n",
    "                        callbacks=[early_stopping, cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aed906c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.3911 - accuracy: 0.9200 - recall_1: 0.2500 - 269ms/epoch - 27ms/step\n",
      "25/25 [==============================] - 0s 13ms/step\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_recall = model.evaluate(X_val_rgb,  y_val, verbose=2, batch_size=10)\n",
    "\n",
    "predictions = (model.predict(X_val_rgb, batch_size=4)>0.5).reshape(1,-1)[0].astype(int)\n",
    "# predictions = model.predict(X_val, batch_size=10)\n",
    "# class_predictions = np.argmax(predictions,axis=1)\n",
    "real_values = y_val.T[0]\n",
    "\n",
    "print(predictions)\n",
    "print(real_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "875e79cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_rgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m X_train_rgb\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m X_val_rgb\n\u001b[1;32m      4\u001b[0m X_test_rgb \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrepeat(X_test[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m100\u001b[39m], \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_rgb' is not defined"
     ]
    }
   ],
   "source": [
    "del X_train_rgb\n",
    "del X_val_rgb\n",
    "\n",
    "X_test_rgb = np.repeat(X_test[0:100], 3, -1)\n",
    "y_test = y_test[:100]\n",
    "del X_test\n",
    "\n",
    "test_loss, test_acc, test_recall = model.evaluate(X_test_rgb,  y_test, verbose=2, batch_size=10)\n",
    "\n",
    "predictions = (model.predict(X_test_rgb, batch_size=4)>0.5).reshape(1,-1)[0].astype(int)\n",
    "# predictions = model.predict(X_val, batch_size=10)\n",
    "real_values = y_test.T[0]\n",
    "\n",
    "print(predictions)\n",
    "print(real_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68b2f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "matthews_corrcoef(real_values, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
